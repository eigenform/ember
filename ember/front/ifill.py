from amaranth import *
from amaranth.lib.enum import *
from amaranth.lib.data import *
from amaranth.lib.wiring import *
import amaranth.lib.memory as memory
from amaranth.utils import exact_log2, ceil_log2

from amaranth_soc.wishbone import Interface as WishboneInterface
from amaranth_soc.wishbone import Signature as WishboneSignature

from ember.common import *
from ember.common.xbar import SimpleCrossbar
from ember.common.coding import EmberPriorityEncoder, ChainedPriorityEncoder
from ember.riscv.paging import *
from ember.param import *
from ember.front.l1i import L1ICacheWritePort
from ember.uarch.front import *
from ember.sim.fakeram import *


class L1IFillRecord(StructLayout):
    def __init__(self, p: EmberParams):
        super().__init__({
            "addr": p.vaddr,
            # Source FTQ index 
            "ftq_idx": p.ftq.index_shape,
            # Number of 32-byte blocks
            "blocks": unsigned(ceil_log2(4)),
            # Way hints for each block
            "ways": ArrayLayout(ceil_log2(p.l1i.num_ways), 4),
        })

class L1IFillSource(Enum, shape=2):
    NONE     = 0
    DEMAND   = 1
    PREFETCH = 2

class L1IFillPort(Signature):
    """ L1I fill unit port. 
    """

    class Request(Signature):
        """ L1 instruction cache fill request.

        .. note::
            Right now, the way index specified by a request is unused,
            and the way used when writing the L1I is generated very late in 
            the process (within in the L1ICache module itself). 

            Currently, the replacement policy implementation for the L1I
            is very ad-hoc. You might want to keep this wire around in case 
            it's useful to select a particular way index earlier in the 
            pipeline. This will probably become clearer when we decide to 
            implement a policy that isn't random. 

        Members
        =======
        valid: 
            This request is valid
        addr: 
            Physical address for this request
        way: 
            Target way in the L1I cache
        ftq_idx:
            Index of the FTQ entry that generated the request
            
        """
        def __init__(self, p: EmberParams):
            super().__init__({
                "valid": Out(1),
                "addr": Out(p.paddr),
                "way": Out(ceil_log2(p.l1i.num_ways)),
                "ftq_idx": Out(p.ftq.index_shape),
                "src": Out(L1IFillSource)
            })

    class Response(Signature):
        """ L1I instruction cache fill response. 

        Members
        =======
        valid:
            This response is valid
        ftq_idx:
            Index of the FTQ entry that generated the request
        way:
            Way index used for the request
        """
        def __init__(self, p: EmberParams):
            super().__init__({
                "valid": Out(1),
                "ftq_idx": Out(p.ftq.index_shape),
                "way": Out(ceil_log2(p.l1i.num_ways)),
                "src": Out(L1IFillSource),
            })

    def __init__(self, p: EmberParams):
        super().__init__({
            "req": Out(self.Request(p)),
            "resp": In(self.Response(p)),
        })





class L1IFillStatus(Signature):
    def __init__(self, p: EmberParams):
        super().__init__({
            "ready":  Out(1),
        })

class L1IMshrState(Enum, shape=2):
    """ The state associated with an MSHR. 

    Values
    ======
    NONE:
        No request is being serviced.
    ACCESS:
        The request is being serviced by a remote memory device.
    WRITEBACK:
        The request data is available and being written back to the L1I
    COMPLETE:
        The request has been completed and is waiting to be released. 
    """
    NONE      = 0
    ACCESS    = 1
    WRITEBACK = 2
    COMPLETE  = 3 


class L1IMissStatusHoldingRegister(Component):
    """ L1I cache "miss-status holding register" (MSHR)

    The L1I fill unit includes MSHRs that are used to track fill requests 
    generated by both demand fetch and prefetch requests that have missed in 
    the L1I cache. An MSHR holds the request while data is being received 
    from memory and written back to the L1I cache data/tag arrays. 

    An MSHR moves through the following sequence of states:

    - ``L1IMshrState.NONE``: Ready to accept a request
    - ``L1IMshrState.ACCESS``: Request is registered and being sent to memory
    - ``L1IMshrState.WRITEBACK``: Response from memory is registered and being
      sent to the IFU and L1I cache write port
    - ``L1IMshrState.COMPLETE``: L1I cache write port response is acknowledged
      and the state of this MSHR is reset

    Upon completion, the L1I fill unit signals the FTQ indicating that the 
    FTQ entry which generated the fill request is eligible to be replayed.

    Ports
    =====
    ready: 
        High when this MSHR is ready to accept a request
    complete:
        High when this MSHR can be reset
    req: 
        Incoming fill request to this MSHR
    l1i_wp: 
        L1I cache write port interface
    fakeram: 
        Memory interface

    """
    def __init__(self, param: EmberParams):
        self.p = param
        signature = Signature({
            "ready": Out(1),
            "complete": In(1),
            #"req": In(L1IFillRequest(param)),
            #"resp": Out(L1IFillResponse(param)),
            "port": In(L1IFillPort(param)),
            "l1i_wp": Out(L1ICacheWritePort(param)),
            "fakeram": Out(FakeRamInterface(param.l1i.line_depth)),
        })
        super().__init__(signature)
        return

    def elaborate(self, platform):
        m = Module()

        state   = Signal(L1IMshrState, init=L1IMshrState.NONE)
        addr    = Signal(self.p.paddr)
        way     = Signal(ceil_log2(self.p.l1i.num_ways))
        ftq_idx = Signal(self.p.ftq.index_shape)
        src     = Signal(L1IFillSource)
        data    = Signal(L1ICacheline(self.p))

        r_ready = Signal(init=1)
        r_addr  = Signal(self.p.paddr)
        r_block = Signal(4)

        m.d.comb += self.ready.eq(r_ready)

        # Drive defaults
        m.d.sync += [
           self.port.resp.valid.eq(0),
           self.port.resp.ftq_idx.eq(0),
           self.port.resp.way.eq(way),
           self.port.resp.src.eq(L1IFillSource.NONE),
        ]


        with m.Switch(state):

            # Idle state.
            # When we get a request, setup to start access on the next cycle.
            with m.Case(L1IMshrState.NONE):
                with m.If(self.port.req.valid):
                    m.d.sync += [
                        state.eq(L1IMshrState.ACCESS),
                        r_ready.eq(0),
                        addr.eq(self.port.req.addr),
                        way.eq(self.port.req.way),
                        ftq_idx.eq(self.port.req.ftq_idx),
                        src.eq(self.port.req.src),
                    ]

            # Interact with a memory device until we have a response.
            # When we get a response [after *at least* one cycle], setup for 
            # L1I writeback on the next cycle.
            with m.Case(L1IMshrState.ACCESS):
                m.d.comb += [
                    self.fakeram.req.addr.eq(addr),
                    self.fakeram.req.valid.eq(1),
                ]
                with m.If(self.fakeram.resp.valid):
                    m.d.sync += [
                        state.eq(L1IMshrState.WRITEBACK),
                        data.eq(Cat(*self.fakeram.resp.data)),

                        # NOTE: Drive ready one cycle early?
                        r_ready.eq(1),
                    ]

            # Write the response data back to the L1I cache.
            #
            # NOTE: Is there any reason why we might want to *wait* a cycle
            # for the response from the L1I write port, or is it okay for us 
            # to just reply and cleanup this MSHR immediately? 
            with m.Case(L1IMshrState.WRITEBACK):
                m.d.comb += [
                    self.l1i_wp.req.valid.eq(1),
                    self.l1i_wp.req.set.eq(addr.l1i.set),
                    self.l1i_wp.req.way.eq(way),
                    self.l1i_wp.req.line_data.eq(data),
                    self.l1i_wp.req.tag_data.ppn.eq(addr.sv32.ppn),
                    self.l1i_wp.req.tag_data.valid.eq(1),
                ]
                m.d.sync += [
                    self.port.resp.valid.eq(1),
                    self.port.resp.ftq_idx.eq(ftq_idx),
                    self.port.resp.way.eq(way),
                    self.port.resp.src.eq(src),

                    state.eq(L1IMshrState.NONE),
                    addr.eq(0),
                    way.eq(0),
                    ftq_idx.eq(0),
                    src.eq(L1IFillSource.NONE),
                    r_ready.eq(1),
                ]

        return m


class NewL1IFillUnit(Component):
    def __init__(self, param: EmberParams):
        self.p = param
        self.num_mshr = param.l1i.fill.num_mshr
        self.num_port = param.l1i.fill.num_port
        signature = Signature({
            "port":     In(L1IFillPort(param)).array(self.num_port),
            "sts":     Out(L1IFillStatus(param)),
            "l1i_wp":  Out(L1ICacheWritePort(param)).array(self.num_mshr),
            "fakeram": Out(FakeRamInterface(param.l1i.line_depth)).array(self.num_mshr),
        })
        super().__init__(signature)

    def elaborate(self, platform):
        m = Module()

        # Logic for mapping requests to available MSHRs
        xbar = m.submodules.xbar = SimpleCrossbar(self.num_port, self.num_mshr)
        xbar_resp = m.submodules.xbar_resp = \
                SimpleCrossbar(self.num_port, self.num_mshr)

        # Instantiate MSHRs
        mshr = []
        for idx in range(self.num_mshr):
            x = m.submodules[f"mshr{idx}"] = L1IMissStatusHoldingRegister(self.p)
            mshr.append(x)

        # Connect MSHRs to resources
        for idx in range(self.num_mshr):
            connect(m, mshr[idx].l1i_wp, flipped(self.l1i_wp[idx]))
            connect(m, mshr[idx].fakeram, flipped(self.fakeram[idx]))

        # Distribute valid requests to available MSHRs
        port_req_valid = [ port.req.valid for port in self.port ]
        mshr_ready    = [ m.ready for m in mshr ]
        m.d.comb += [
            xbar.upstream_grant.eq(Cat(*port_req_valid)),
            xbar.downstream_grant.eq(Cat(*mshr_ready)),
            self.sts.ready.eq(Cat(*mshr_ready).any()),
        ]
        # Distribute responses from completed MSHRs to output ports
        mshr_resp_valid = [ m.port.resp.valid for m in mshr ]
        m.d.comb += [
            xbar_resp.upstream_grant.eq(C(3, self.num_port)),
            xbar_resp.downstream_grant.eq(Cat(*mshr_resp_valid)),
        ]


        # Where 'N' is the number of ports, and 'M' is the number of MSHRs: 
        #
        #                 N-to-N            N-to-M           M-to-M         
        #  self.port.req|=======>|req_in  |========|req_out|=======>|mshr.req
        #               |        |        |  xbar  |       |        |
        #               |        |        |        |       |        |          
        #               |        |        |  xbar  |       |        |
        # self.port.resp|<=======|resp_out|========|resp_in|<=======|mshr.resp
        #                 N-to-N            N-to-M           M-to-M
        #


        # Connect ports to wires
        req_in = Array(L1IFillPort.Request(self.p).flip().create() for _ in range(self.num_port))
        resp_out = Array(L1IFillPort.Response(self.p).create() for _ in range(self.num_port))
        for port_idx in range(self.num_port):
            connect(m, flipped(self.port[port_idx].req), req_in[port_idx])
            connect(m, resp_out[port_idx], flipped(self.port[port_idx].resp))

        # Connect wires to MSHRs
        req_out = Array(L1IFillPort.Request(self.p).create() for _ in range(self.num_mshr))
        resp_in = Array(L1IFillPort.Response(self.p).create() for _ in range(self.num_mshr))
        for mshr_idx in range(self.num_mshr):
            connect(m, req_out[mshr_idx], mshr[mshr_idx].port.req)
            connect(m, mshr[mshr_idx].port.resp, flipped(resp_in[mshr_idx]))

        # Default assignments
        for idx in range(self.num_port):
            m.d.comb += [
                req_out[idx].valid.eq(0),
                req_out[idx].addr.eq(0),
                req_out[idx].way.eq(0),
                req_out[idx].ftq_idx.eq(0),
                resp_out[idx].valid.eq(0),
                resp_out[idx].ftq_idx.eq(0),
                resp_out[idx].src.eq(L1IFillSource.NONE),
            ]

        for idx in range(self.num_port):
            with m.If(xbar.grant[idx]): 
                mshr_idx = xbar.dst_idx[idx]
                m.d.comb += [
                    #Print(Format("port_req{} -> mshr_req{}", idx, mshr_idx)),
                    req_out[mshr_idx].valid.eq(req_in[idx].valid),
                    req_out[mshr_idx].addr.eq(req_in[idx].addr),
                    req_out[mshr_idx].way.eq(req_in[idx].way),
                    req_out[mshr_idx].ftq_idx.eq(req_in[idx].ftq_idx),
                    req_out[mshr_idx].src.eq(req_in[idx].src),
                ]

        for idx in range(self.num_port):
            with m.If(xbar_resp.grant[idx]): 
                mshr_idx = xbar_resp.dst_idx[idx]
                m.d.comb += [
                    #Print(Format("mshr_resp{} -> port_resp{}", mshr_idx, idx)),
                    resp_out[idx].valid.eq(resp_in[mshr_idx].valid),
                    resp_out[idx].ftq_idx.eq(resp_in[mshr_idx].ftq_idx),
                    resp_out[idx].src.eq(resp_in[mshr_idx].src),
                ]

        return m


#class L1IMshrArbiter(Component):
#    """ Arbiter for controlling a set of MSHRs. 
#
#    Parameters
#    ==========
#    num_mshr: int
#        The number of MSHRs
#    width: int
#        The number of fill requests/responses 
#
#    Ports
#    =====
#    ready:
#        High when at least one MSHR is available to service a request.
#
#    ifill_req: L1IFillRequest
#        Fill requests to-be-forwarded to available MSHRs.
#    ifill_resp: L1IFillResponse
#        Fill responses from an MSHR which has completed
#
#    mshr_ready:
#        Array of ready signals for each MSHR
#    mshr_complete:
#        Array of complete signals for each MSHR
#    mshr_req: 
#        Fill request wires for each MSHR
#    mshr_resp:
#        Fill response wires for each MSHR
#
#    """
#    def __init__(self, param: EmberParams, num_mshr: int, width: int):
#        self.p = param
#        self.num_mshr = num_mshr
#        self.width = width
#        sig = Signature({
#            "ready": Out(1),
#            "ifill_req": In(L1IFillPort.Request(param)).array(2),
#            "ifill_resp": Out(L1IFillPort.Response(param)).array(2),
#
#            "mshr_ready": In(1).array(num_mshr),
#            "mshr_complete": Out(1).array(num_mshr),
#            "mshr_req": Out(L1IFillPort.Request(param)).array(num_mshr),
#            "mshr_resp": In(L1IFillPort.Response(param)).array(num_mshr),
#        })
#        super().__init__(sig)
#
#    def elaborate(self, platform):
#        m = Module()
#
#        # Outgoing requests to MSHRs
#        req_arr = Array(
#            L1IFillPort.Request(self.p).create() for _ in range(self.num_mshr)
#        )
#        # Incoming responses from MSHRs
#        resp_arr = Array(
#            L1IFillPort.Response(self.p).flip().create() for _ in range(self.num_mshr)
#        )
#        # Incoming 'ready' signals from MSHRs
#        ready_arr = Array(Signal() for _ in range(self.num_mshr))
#        # Incoming 'complete' signals from MSHRs
#        complete_arr = Array(Signal() for _ in range(self.num_mshr))
#
#        # Connect ports to intermediate wires
#        for idx in range(self.num_mshr):
#            connect(m, req_arr[idx], flipped(self.mshr_req[idx]))
#            connect(m, flipped(self.mshr_resp[idx]), resp_arr[idx])
#            m.d.comb += [
#                self.mshr_complete[idx].eq(complete_arr[idx]),
#                ready_arr[idx].eq(self.mshr_ready[idx]),
#            ]
#
#        # The arbiter is "ready" when at least one MSHR is ready
#        m.d.comb += self.ready.eq(Cat(*ready_arr).any())
#
#
#
#        # Select up to two free MSHRs
#        ready_enc = m.submodules.ready_encoder = \
#                ChainedPriorityEncoder(self.num_mshr, depth=2)
#        m.d.comb += ready_enc.i.eq(Cat(*ready_arr))
#        num_ready = popcount(Cat(*ready_enc.valid))
#        num_req   = popcount(Cat([self.ifill_req[ridx].valid for ridx in range(2)]))
#
#        # Select completed MSHRs
#        complete_enc = m.submodules.complete_encoder = \
#                ChainedPriorityEncoder(self.num_mshr, depth=2)
#
#        valids = [ resp_arr[idx].valid for idx in range(self.num_mshr) ]
#        m.d.comb += complete_enc.i.eq(Cat(*valids))
#        num_complete = popcount(Cat(*complete_enc.valid))
#        #num_resp   = popcount(Cat([self.resp[ridx].valid for ridx in range(2)]))
#
#        #for i in range(2):
#        #    m.d.comb += [
#        #        Print(Format("IFILL complete slot {}: idx={},valid={}",
#        #            idx, complete_enc.o[idx],complete_enc.valid[idx]
#        #        ))
#        #    ]
#
#        # Default assignment
#        for idx in range(self.num_mshr):
#            m.d.comb += [
#                req_arr[idx].valid.eq(0),
#                req_arr[idx].addr.eq(0),
#                req_arr[idx].way.eq(0),
#                req_arr[idx].ftq_idx.eq(0),
#                complete_arr[idx].eq(0),
#            ]
#
#        for ridx in range(2):
#            # Allocate
#            with m.If(self.ifill_req[ridx].valid & ready_enc.valid[ridx]):
#                mshr_idx = ready_enc.o[ridx]
#                m.d.comb += [
#                    req_arr[mshr_idx].valid.eq(self.ifill_req[ridx].valid),
#                    req_arr[mshr_idx].addr.eq(self.ifill_req[ridx].addr),
#                    req_arr[mshr_idx].way.eq(self.ifill_req[ridx].way),
#                    req_arr[mshr_idx].ftq_idx.eq(self.ifill_req[ridx].ftq_idx),
#                ]
#            # Complete
#            with m.If(complete_enc.valid[ridx]):
#                mshr_idx = complete_enc.o[ridx]
#                m.d.comb += [
#                    complete_arr[mshr_idx].eq(1),
#                    self.ifill_resp[ridx].valid.eq(resp_arr[mshr_idx].valid),
#                    self.ifill_resp[ridx].ftq_idx.eq(resp_arr[mshr_idx].ftq_idx),
#                ]
#
#        return m
#
#class L1IFillUnit(Component):
#    """ Logic for moving bytes from remote memory into the L1I cache.
#
#    The L1I fill unit tracks outstanding cache misses until data has been 
#    written back to the L1I data/tag arrays. Each pending miss is held in 
#    an MSHR until L1I writeback is complete. 
#
#    Handling multiple misses in parallel allows misses generated by prefetch 
#    requests to begin/complete without blocking for misses generated by demand 
#    fetch requests. 
#
#    The :class:`L1IMshrArbiter` forwards fill requests to an available MSHR. 
#
#    Ports
#    =====
#    sts: 
#        Fill unit status driven [upstream] to instruction fetch logic
#    l1i_wp: 
#        L1I cache write port[s]
#    req: 
#        Fill request from instruction fetch logic
#    resp: 
#        Response to the FTQ
#    fakeram: 
#        Interface[s] to a mock RAM device
#
#    """
#    def __init__(self, param: EmberParams):
#        self.p = param
#        num_mshr = param.l1i.fill.num_mshr
#        signature = Signature({
#            "sts":     Out(L1IFillStatus(param)),
#            "l1i_wp":  Out(L1ICacheWritePort(param)).array(num_mshr),
#            "req":      In(L1IFillPort.Request(param)).array(2),
#            "resp":    Out(L1IFillPort.Response(param)).array(2),
#            "fakeram": Out(FakeRamInterface(param.l1i.line_depth)).array(num_mshr),
#        })
#        super().__init__(signature)
#
#    def elaborate(self, platform):
#        m = Module()
#
#        # Instantiate a set of MSHRs
#        mshr = []
#        for idx in range(self.p.l1i.fill.num_mshr):
#            x = m.submodules[f"mshr{idx}"] = L1IMissStatusHoldingRegister(self.p)
#            mshr.append(x)
#
#        # Instantiate the arbiter
#        arb = m.submodules.arb = L1IMshrArbiter(
#            self.p, 
#            width=2, 
#            num_mshr=self.p.l1i.fill.num_mshr,
#        )
#
#        # Connect MSHRs to the arbiter
#        connect(m, arb.ifill_req[0], flipped(self.req[0]))
#        connect(m, arb.ifill_req[1], flipped(self.req[1]))
#        connect(m, arb.ifill_resp[0], flipped(self.resp[0]))
#        connect(m, arb.ifill_resp[1], flipped(self.resp[1]))
#        m.d.comb += self.sts.ready.eq(arb.ready)
#
#        # FIXME: Each MSHR has its own L1I write port and memory interface? 
#        for idx in range(self.p.l1i.fill.num_mshr):
#            m.d.comb += arb.mshr_ready[idx].eq(mshr[idx].ready)
#            m.d.comb += mshr[idx].complete.eq(arb.mshr_complete[idx])
#            connect(m, mshr[idx].port.req, arb.mshr_req[idx])
#            connect(m, mshr[idx].port.resp, arb.mshr_resp[idx])
#            connect(m, mshr[idx].l1i_wp, flipped(self.l1i_wp[idx]))
#            connect(m, mshr[idx].fakeram, flipped(self.fakeram[idx]))
#
#        return m


